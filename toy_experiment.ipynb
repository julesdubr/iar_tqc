{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from single_state_mdp import SingleStateMDP\n",
    "from structures import Trainer, Critic, ReplayBuffer\n",
    "\n",
    "seeds = np.random.randint(0, 2**32-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.3236619234085083 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.36168086528778076 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.29764890670776367 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.34267139434814453 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "averages : 428.56835174560547 - 50.91926517486572\n",
      "variances : 44.031157922744754 - 0.10818810909986495\n",
      "distances : 0.7346673011779785 - 0.8073036670684814\n"
     ]
    }
   ],
   "source": [
    "min1_means = np.zeros((10))\n",
    "min1_variances = np.zeros((10))\n",
    "min1_distances = np.zeros((10))\n",
    "\n",
    "min2_means = np.zeros((10))\n",
    "min2_variances = np.zeros((10))\n",
    "min2_distances = np.zeros((10))\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    # Setup env\n",
    "    env = SingleStateMDP(seed=seed)\n",
    "\n",
    "    # Setup Q-networks\n",
    "    critic1 = Critic(n_nets=10)\n",
    "    critic2 = Critic(n_nets=10)\n",
    "    min_trainer1 = Trainer(critic1, bias_correction_method=\"MIN\")\n",
    "    min_trainer2 = Trainer(critic2, bias_correction_method=\"MIN2\")\n",
    "\n",
    "    # Training the critic\n",
    "    train_action_grid = torch.linspace(-1, 1, 50)\n",
    "    train_replay_buffer = ReplayBuffer(env, train_action_grid, max_size=50)\n",
    "\n",
    "    min_trainer1.train(train_replay_buffer, 3000)\n",
    "    min_trainer2.train(train_replay_buffer, 3000)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_action_grid = torch.linspace(-1, 1, 2000)\n",
    "    eval_replay_buffer = ReplayBuffer(env, eval_action_grid, max_size=2000)\n",
    "\n",
    "    mean1, var1, dist1 = min_trainer1.evaluate(env, eval_replay_buffer, verbose=1)\n",
    "    mean2, var2, dist2 = min_trainer2.evaluate(env, eval_replay_buffer, verbose=1)\n",
    "\n",
    "    min1_means[i] = mean1\n",
    "    min1_variances[i] = var1\n",
    "    min1_distances[i] = dist1\n",
    "\n",
    "    min2_means[i] = mean2\n",
    "    min2_variances[i] = var2\n",
    "    min2_distances[i] = dist2\n",
    "\n",
    "print(f\"averages : {min1_means.mean()} - {min2_means.mean()}\")\n",
    "print(f\"variances : {min1_variances.mean()} - {min2_variances.mean()}\")\n",
    "print(f\"distances : {min1_distances.mean()} - {min2_distances.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax: 0.1135568618774414 - a*: 0.33166587352752686\n",
      "argmax: -0.16058027744293213 - a*: 0.33166587352752686\n",
      "argmax: 0.15857934951782227 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: -0.0985492467880249 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.08454227447509766 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: -0.09654825925827026 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.09354686737060547 - a*: 0.33166587352752686\n",
      "argmax: -0.17358678579330444 - a*: 0.33166587352752686\n",
      "argmax: 0.15557777881622314 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: 0.22961485385894775 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "argmax: -1.0 - a*: 0.33166587352752686\n",
      "averages : 1620.9749633789063 - 976.980093383789\n",
      "variances: 71.92374448776245 - 12.033921999484301\n",
      "distances: 0.40130065083503724 - 1.1650825798511506\n"
     ]
    }
   ],
   "source": [
    "mean1_means = np.zeros((10))\n",
    "mean1_variances = np.zeros((10))\n",
    "mean1_distances = np.zeros((10))\n",
    "\n",
    "mean2_means = np.zeros((10))\n",
    "mean2_variances = np.zeros((10))\n",
    "mean2_distances = np.zeros((10))\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    # Setup env\n",
    "    env = SingleStateMDP(seed=seed)\n",
    "\n",
    "    # Setup Q-networks\n",
    "    critic1 = Critic(n_nets=10)\n",
    "    critic2 = Critic(n_nets=10)\n",
    "    mean_trainer1 = Trainer(critic1, bias_correction_method=\"AVG\")\n",
    "    mean_trainer2 = Trainer(critic2, bias_correction_method=\"AVG2\")\n",
    "\n",
    "    # Training the critic\n",
    "    train_action_grid = torch.linspace(-1, 1, 50)\n",
    "    train_replay_buffer = ReplayBuffer(env, train_action_grid, max_size=50)\n",
    "\n",
    "    mean_trainer1.train(train_replay_buffer, 3000)\n",
    "    mean_trainer2.train(train_replay_buffer, 3000)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_action_grid = torch.linspace(-1, 1, 2000)\n",
    "    eval_replay_buffer = ReplayBuffer(env, eval_action_grid, max_size=2000)\n",
    "\n",
    "    mean1, var1, dist1 = mean_trainer1.evaluate(env, eval_replay_buffer, verbose=1)\n",
    "    mean2, var2, dist2 = mean_trainer2.evaluate(env, eval_replay_buffer, verbose=1)\n",
    "\n",
    "    mean1_means[i] = mean1\n",
    "    mean1_variances[i] = var1\n",
    "    mean1_distances[i] = dist1\n",
    "\n",
    "    mean2_means[i] = mean2\n",
    "    mean2_variances[i] = var2\n",
    "    mean2_distances[i] = dist2\n",
    "\n",
    "print(f\"averages : {mean1_means.mean()} - {mean2_means.mean()}\")\n",
    "print(f\"variances: {mean1_variances.mean()} - {mean2_variances.mean()}\")\n",
    "print(f\"distances: {mean1_distances.mean()} - {mean2_distances.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14f325d447890c1aa81d5004c3a59981b75ede9581a60409be6700f02a9947e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
