{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from single_state_mdp import SingleStateMDP\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    # Define and return an instance of the SingleStateMDP environment\n",
    "    return SingleStateMDP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TQC agent with specified parameters\n",
    "policy_kwargs = {\"n_quantiles\": 25, \"n_critics\": 2, \"net_arch\": [50,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_to_drop = [0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 16]\n",
    "agents = [None] * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] 0.607 +/- 0.280\n",
      "[1] 0.561 +/- 0.261\n",
      "[2] 0.608 +/- 0.251\n",
      "[3] 0.635 +/- 0.250\n",
      "[4] 0.574 +/- 0.257\n",
      "[5] 0.593 +/- 0.267\n",
      "[6] 0.632 +/- 0.233\n",
      "[7] 0.617 +/- 0.236\n",
      "[10] 0.586 +/- 0.227\n",
      "[13] 0.617 +/- 0.235\n",
      "[16] 0.571 +/- 0.240\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(quantiles_to_drop):\n",
    "    env = make_env()\n",
    "    eval_env = Monitor(make_env())\n",
    "\n",
    "    agents[i] = TQC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, top_quantiles_to_drop_per_net=d)\n",
    "    # Train the agent for the desired number of iterations\n",
    "    agents[i].learn(total_timesteps=3000)\n",
    "\n",
    "    # Evaluate the performance of the TQC agent using the evaluate_policy function\n",
    "    mean_rewards, std_rewards = evaluate_policy(agents[i], eval_env, n_eval_episodes=100)\n",
    "\n",
    "    print(f'[{d}] {mean_rewards:.3f} +/- {std_rewards:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.zeros((11,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed Discrepency: 0.104 +/- 0.473\n",
      "Signed Discrepency: 0.121 +/- 0.472\n",
      "Signed Discrepency: 0.105 +/- 0.467\n",
      "Signed Discrepency: 0.113 +/- 0.463\n",
      "Signed Discrepency: 0.105 +/- 0.474\n",
      "Signed Discrepency: 0.103 +/- 0.473\n",
      "Signed Discrepency: 0.110 +/- 0.463\n",
      "Signed Discrepency: 0.120 +/- 0.478\n",
      "Signed Discrepency: 0.098 +/- 0.465\n",
      "Signed Discrepency: 0.091 +/- 0.473\n",
      "Signed Discrepency: 0.105 +/- 0.467\n"
     ]
    }
   ],
   "source": [
    "# Define a dense uniform grid of actions to evaluate the approximations on\n",
    "actions = np.linspace(-1, 1, 2000)\n",
    "\n",
    "# Initialize arrays to store the results\n",
    "signed_discrepancies = np.zeros(actions.shape)\n",
    "\n",
    "for i, agent in enumerate(agents):\n",
    "    # Evaluate the performance of the TQC agent on the dense uniform grid of actions\n",
    "    for j, action in enumerate(actions):\n",
    "        # Get the approximate Q-value for the current action\n",
    "        q_value, _ = agent.predict(np.array([0]), np.array([action]))\n",
    "        \n",
    "        # Calculate the signed discrepancy between the approximate Q-value and the true Q-value\n",
    "        signed_discrepancy = q_value - env._mean_reward(action)\n",
    "        \n",
    "        # Store the results\n",
    "        signed_discrepancies[j] = signed_discrepancy\n",
    "\n",
    "    points[i,0] = signed_discrepancies.mean()\n",
    "    points[i,1] = signed_discrepancies.std()\n",
    "\n",
    "    print(f'Signed Discrepency: {signed_discrepancies.mean():.3f} +/- {signed_discrepancies.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f455099f1d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(points[:,0], points[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from single_state_mdp import SingleStateMDP\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_huber_loss_f(quantiles, samples):\n",
    "    pairwise_delta = samples[:, None, None, :] - quantiles[:, :, :, None]  # batch x nets x quantiles x samples\n",
    "    abs_pairwise_delta = torch.abs(pairwise_delta)\n",
    "    huber_loss = torch.where(abs_pairwise_delta > 1,\n",
    "                             abs_pairwise_delta - 0.5,\n",
    "                             pairwise_delta ** 2 * 0.5)\n",
    "\n",
    "    n_quantiles = quantiles.shape[2]\n",
    "    tau = torch.arange(n_quantiles, device=DEVICE).float() / n_quantiles + 1 / 2 / n_quantiles\n",
    "    loss = (torch.abs(tau[None, None, :, None] - (pairwise_delta < 0).float()) * huber_loss).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim, action_dim, n_nets, n_quantiles, dropped_quantiles=1, bias_correction_method=\"AVG\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_quantiles = n_quantiles\n",
    "        self.dropped_quantiles = dropped_quantiles\n",
    "        self.n_nets = n_nets\n",
    "        self.bias_correction_method = bias_correction_method\n",
    "\n",
    "        # Define a list of Q-networks with the given architecture\n",
    "        self.nets = [\n",
    "            nn.Sequential(\n",
    "                nn.Linear(state_dim + action_dim, 50),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 50),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, n_quantiles),\n",
    "            )\n",
    "            for _ in range(n_nets)\n",
    "        ]\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        # sa = torch.cat((state, action), dim=1)\n",
    "        sa = torch.tensor((state, action))\n",
    "        quantiles = torch.stack(tuple(net(sa) for net in self.nets), dim=1)\n",
    "        return quantiles\n",
    "\n",
    "    def train(self, replay_buffer, optimizer, num_iterations=3000):\n",
    "        for i in range(num_iterations):\n",
    "            # Sample a batch of transitions from the replay buffer\n",
    "            state, action, reward, next_state, done = replay_buffer.sample()\n",
    "\n",
    "            # Calculate the target Q-value for each transition\n",
    "            with torch.no_grad():\n",
    "                next_mean, next_variance = self(next_state, action)\n",
    "                target = reward + (1 - done) * self.gamma * next_mean\n",
    "\n",
    "            # Calculate the loss for the Q-network\n",
    "            mean, variance = self(state, action)\n",
    "            loss = 0\n",
    "            if self.bias_correction_method == 'AVG':\n",
    "                # Calculate the loss using the mean of the Q-value distribution\n",
    "                loss = F.mse_loss(mean, target)\n",
    "            elif self.bias_correction_method == 'MIN':\n",
    "                # Calculate the loss using the minimum value of the Q-value distribution\n",
    "                loss = F.mse_loss(mean.min(dim=1, keepdim=True)[0], target)\n",
    "            elif self.bias_correction_method == 'TQC':\n",
    "                # Calculate the loss using the TQC bias correction method\n",
    "                sorted_quantiles, _ = torch.sort(mean, dim=1)\n",
    "                quantile_values = sorted_quantiles[:, :self.n_quantiles-self.dropped_quantiles]\n",
    "                loss = quantile_huber_loss_f(quantile_values, target)\n",
    "\n",
    "            # Backpropagate the loss and update the weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def predict(self, action):\n",
    "        # Evaluate each Q-network on the given action and return a list of the corresponding approximate Q-values\n",
    "        return [network(action).item() for network in self.nets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, env, size):\n",
    "        self.transitions = []\n",
    "\n",
    "        for action in np.linspace(-1., 1., size):\n",
    "            state = 0\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            self.transitions.append((state, action, next_state, reward, done))\n",
    "\n",
    "    def sample(self):\n",
    "        return random.choice(self.transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SingleStateMDP()\n",
    "state_dim = env.observation_space.n\n",
    "action_dim = env.action_space.shape[0]\n",
    "critic = Critic(state_dim, action_dim, 3, 25, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tqc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14f325d447890c1aa81d5004c3a59981b75ede9581a60409be6700f02a9947e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
